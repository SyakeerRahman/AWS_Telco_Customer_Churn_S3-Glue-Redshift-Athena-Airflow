<img width="455" alt="image" src="https://github.com/user-attachments/assets/a0151c66-e457-402b-bb60-563161b32c7e" /># AWS_Telco_Customer_Churn_S3-Glue-Redshift-Athena-Airflow

![image](https://github.com/user-attachments/assets/1d06724a-359b-4dd9-8f94-cf4a503e9e77)

Telco Customer Churn Data Pipeline 
AWS Cloud Data Engineering Project 

I want to share my latest Data Engineering project where I put my skills to the test by working with an AWS cloud using Databricks and load into BI tools.

🔬𝗣𝗿𝗼𝗷𝗲𝗰𝘁 𝗢𝘃𝗲𝗿𝘃𝗶𝗲𝘄: End-to-end data engineering on AWS. Where I ingested data from S3 to Redshift using Glue, transformed it with Glue, loaded it into Athena and Redshift, and reported with BI tools. Also used IAM and VPC for data governance. More information can be found in the GitHub repository.

💾 𝗗𝗮𝘁𝗮 𝗦𝗼𝘂𝗿𝗰𝗲: https://www.kaggle.com/datasets/blastchar/telco-customer-churn/code

🎯 𝗣𝗿𝗼𝗷𝗲𝗰𝘁 𝗚𝗼𝗮𝗹𝘀:

• Store data in S3.
• Run Airflow on EC2
• Transform and clean with Glue
• Load data into Redshift.
• Create interactive reports with BI tools
• Implement IAM and VPC for governance.

 🔧The tools that are covered in this project are:

1. Amazon S3
2. Amazon EC2
3. Amazon IAM
4. Amazon VPC
5. Amazon Glue
6. Amazon Redshift
7. Amazon Athena


## 1. Run EC2 to Install Airflow

### 1.1 Setting up EC2

On EC2 page launch instance
  
<img width="947" alt="image" src="https://github.com/user-attachments/assets/66a82317-ad2b-48bf-a322-b0b687c6b6ce" />
<img width="444" alt="image" src="https://github.com/user-attachments/assets/ba20f5a9-9c1c-4f04-8fa9-59e9bded9a2e" />
<img width="437" alt="image" src="https://github.com/user-attachments/assets/6aae095c-9d9e-4083-ad99-b49af6cdeb22" />
<img width="455" alt="image" src="https://github.com/user-attachments/assets/600185c8-5722-4cef-b0a8-2ea688c0ef86" />

### 1.2 Connect to Instances
<img width="404" alt="image" src="https://github.com/user-attachments/assets/cb04d595-8848-42b6-9675-27a867790068" />

