# AWS_Telco_Customer_Churn_S3-Glue-Redshift-Athena-Airflow

![image](https://github.com/user-attachments/assets/1d06724a-359b-4dd9-8f94-cf4a503e9e77)

Telco Customer Churn Data Pipeline 
AWS Cloud Data Engineering Project 

I want to share my latest Data Engineering project where I put my skills to the test by working with an AWS cloud using Databricks and load into BI tools.

ğŸ”¬ğ—£ğ—¿ğ—¼ğ—·ğ—²ğ—°ğ˜ ğ—¢ğ˜ƒğ—²ğ—¿ğ˜ƒğ—¶ğ—²ğ˜„: End-to-end data engineering on AWS. Where I ingested data from S3 to Redshift using Glue, transformed it with Glue, loaded it into Athena and Redshift, and reported with BI tools. Also used IAM and VPC for data governance. More information can be found in the GitHub repository.

ğŸ’¾ ğ——ğ—®ğ˜ğ—® ğ—¦ğ—¼ğ˜‚ğ—¿ğ—°ğ—²: https://www.kaggle.com/datasets/blastchar/telco-customer-churn/code

ğŸ¯ ğ—£ğ—¿ğ—¼ğ—·ğ—²ğ—°ğ˜ ğ—šğ—¼ğ—®ğ—¹ğ˜€:

â€¢ Store data in S3.
â€¢ Run Airflow on EC2
â€¢ Transform and clean with Glue
â€¢ Load data into Redshift.
â€¢ Create interactive reports with BI tools
â€¢ Implement IAM and VPC for governance.

 ğŸ”§The tools that are covered in this project are:

1. Amazon S3
2. Amazon EC2
3. Amazon IAM
4. Amazon VPC
5. Amazon Glue
6. Amazon Redshift
7. Amazon Athena


## 1. Run EC2 to Install Airflow

### 1.1 Setting up EC2

On EC2 page launch instance
  
<img width="947" alt="image" src="https://github.com/user-attachments/assets/66a82317-ad2b-48bf-a322-b0b687c6b6ce" />
![image](https://github.com/user-attachments/assets/6433be96-721d-4da9-b3bf-1b8771ce2e41)
![image](https://github.com/user-attachments/assets/cc054391-1f9d-4229-91c4-5ca4ca65ce4e)
![image](https://github.com/user-attachments/assets/f1d591c3-940f-4738-82ec-44a2aa9bf4e0)



